import os
import sys
from dotenv import load_dotenv

# Importa√ß√µes Padr√£o
from agentCore.providers import get_llm
from agentCore.logger import get_logger
from crewai import Agent, Task, Crew, Process
from langchain_ollama import ChatOllama
from agentCore.evaluation import PromptEvaluator

load_dotenv()

# Desabilitar traces online do CrewAI
os.environ["CREWAI_TELEMETRY_ENABLED"] = "false"

logger = get_logger("crewai_ollama_demo")

def criar_e_executar_time_ia(llm_instance):
    pesquisador = Agent(
        role='Pesquisador S√™nior de IA',
        goal='Encontrar os desenvolvimentos e impactos mais recentes da IA no desenvolvimento de software',
        backstory="Voc√™ √© um pesquisador experiente, mestre em encontrar informa√ß√µes complexas e destilar os pontos-chave. SEMPRE responda em portugu√™s brasileiro.",
        verbose=True,
        allow_delegation=False,
        llm=llm_instance,
    )
    escritor = Agent(
        role='Escritor T√©cnico Especialista',
        goal='Criar um relat√≥rio claro, conciso e informativo sobre o impacto da IA no desenvolvimento de software',
        backstory="Voc√™ √© um escritor renomado por transformar dados t√©cnicos em narrativas envolventes para executivos. SEMPRE escreva em portugu√™s brasileiro.",
        verbose=True,
        allow_delegation=False,
        llm=llm_instance,
    )
    tarefa_pesquisa = Task(
        description=("1. Pesquise as principais maneiras pelas quais a IA est√° mudando o ciclo de vida do desenvolvimento de software (SDLC).\n"
                     "2. Identifique 3 a 5 ferramentas de IA populares que desenvolvedores est√£o usando hoje.\n"
                     "3. Analise tanto os benef√≠cios (ex: produtividade) quanto os desafios (ex: qualidade do c√≥digo, seguran√ßa).\n"
                     "4. Compile suas descobertas em notas detalhadas para o escritor.\n"
                     "IMPORTANTE: Responda sempre em portugu√™s brasileiro."),
        expected_output='Um boletim com os pontos principais, exemplos de ferramentas e uma an√°lise de pr√≥s e contras.',
        agent=pesquisador,
    )
    tarefa_escrita = Task(
        description=("USANDO O CONTEXTO FORNECIDO, que cont√©m as notas detalhadas de um pesquisador, siga estes passos:\n"
                     "1. Escreva um relat√≥rio de 2 par√°grafos sobre o impacto da IA no desenvolvimento de software.\n"
                     "2. O relat√≥rio deve ser direcionado a um p√∫blico de gest√£o (executivos, diretores), evitando jarg√µes muito t√©cnicos.\n"
                     "3. Comece com um resumo do impacto geral, depois detalhe os benef√≠cios e desafios encontrados no contexto.\n"
                     "4. Finalize com uma conclus√£o sobre o futuro do desenvolvimento de software com IA.\n"
                     "N√ÉO use ferramentas. Toda a informa√ß√£o de que precisa est√° no contexto.\n"
                     "IMPORTANTE: Escreva sempre em portugu√™s brasileiro."),
        expected_output='Um relat√≥rio bem estruturado em formato markdown, baseado unicamente nas notas da pesquisa fornecidas.',
        agent=escritor,
        context=[tarefa_pesquisa]
    )
    time_de_ia = Crew(
        agents=[pesquisador, escritor],
        tasks=[tarefa_pesquisa, tarefa_escrita],
        process=Process.sequential,
        verbose=True
    )
    logger.progress(f"üöÄ A executar o time de agentes com o modelo: {getattr(llm_instance, 'model', 'unknown')}...")
    resultado = time_de_ia.kickoff()
    return resultado

def demo_model_comparison():
    logger.info("‚öîÔ∏è Iniciando Demo de Compara√ß√£o de Modelos")
    modelos_para_comparar = ["llama3", "mistral"]
    resultados_por_modelo = []
    base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

    for nome_modelo in modelos_para_comparar:
        print("\n" + "="*50)
        logger.info(f"‚öôÔ∏è A preparar a execu√ß√£o para o modelo: {nome_modelo}")
        
        # Criamos uma inst√¢ncia especial do LLM para o CrewAI com o prefixo
        llm_para_crewai = ChatOllama(model=f"ollama/{nome_modelo}", base_url=base_url)
        
        # Executamos o time com esta inst√¢ncia especial
        resultado = criar_e_executar_time_ia(llm_para_crewai)
        
        print(f"\nüìÑ Relat√≥rio Gerado por '{nome_modelo}':\n{resultado}")
        
        resultados_por_modelo.append({
            "provider": nome_modelo,
            "prompt": "Gerar um relat√≥rio sobre o impacto da IA no desenvolvimento de software.",
            "actual": resultado
        })

    logger.info("‚öñÔ∏è A comparar os resultados gerados...")
    
    # O avaliador usar√° o get_llm() padr√£o, que agora est√° corrigido e n√£o usa o prefixo.
    # Ele usar√° o modelo definido em OLLAMA_MODEL ou o padr√£o 'llama3' para julgar.
    os.environ['OLLAMA_MODEL'] = 'llama3' # Usamos sempre o mesmo juiz
    evaluator = PromptEvaluator(llm_provider="ollama")
    scores = {}

    for res in resultados_por_modelo:
        avaliacao = evaluator.evaluate_single(
            prompt=f"Voc√™ √© um especialista em tecnologia. Avalie a qualidade e clareza do seguinte relat√≥rio numa escala de 0.0 a 1.0. Relat√≥rio: '{res['actual']}'",
            expected=("Um relat√≥rio excelente, conciso e bem estruturado sobre o impacto da IA no SDLC, "
                      "mencionando ferramentas, benef√≠cios e desafios, com uma linguagem clara para executivos."),
            eval_type="semantic_similarity"
        )
        scores[res['provider']] = avaliacao.score

    print("\n" + "="*50)
    logger.success("‚öîÔ∏è Resultado da Compara√ß√£o ‚öîÔ∏è")
    print("="*50)
    for modelo, score in scores.items():
        print(f"üéñÔ∏è Modelo: {modelo:<10} | Score: {score:.2f}")
    
    melhor_modelo = max(scores, key=scores.get)
    print(f"\nüèÜ Melhor Modelo para esta tarefa: {melhor_modelo.upper()}")
    print("="*50)

if __name__ == "__main__":
    demo_model_comparison()
    print("‚úÖ Script conclu√≠do.")