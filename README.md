# AgentCore

Uma biblioteca Python abrangente para construir agentes de IA com integra√ß√£o de ferramentas e suporte a m√∫ltiplos provedores LLM.

## üöÄ Caracter√≠sticas Principais

- **Multi-provedor LLM**: AWS Bedrock (principal), OpenAI, Ollama, Google Gemini
- **Convers√£o autom√°tica de APIs**: Transforme especifica√ß√µes OpenAPI em ferramentas LangGraph
- **Base vetorial integrada**: Suporte nativo ao ChromaDB
- **Orquestra√ß√£o de agentes**: Baseado em LangGraph para fluxos complexos
- **Logging profissional**: Sistema de logs estruturado e colorido
- **F√°cil instala√ß√£o**: Dispon√≠vel via pip

## üì¶ Instala√ß√£o

### Instala√ß√£o b√°sica
```bash
pip install agentcore
```

### Instala√ß√£o com provedores espec√≠ficos
```bash
# AWS Bedrock (recomendado para produ√ß√£o)
pip install agentcore[aws]

# OpenAI
pip install agentcore[openai]

# Ollama (desenvolvimento local)
pip install agentcore[ollama]

# Google Gemini
pip install agentcore[google]

# Todas as depend√™ncias
pip install agentcore[aws,openai,ollama,google]
```

### Para desenvolvimento
```bash
pip install agentcore[dev]
```

## üõ†Ô∏è Uso R√°pido

### 1. Convers√£o de API para Ferramentas

A funcionalidade principal da biblioteca √© converter especifica√ß√µes OpenAPI em ferramentas utiliz√°veis:

```python
from agentCore.utils import api2tool

# Converter OpenAPI para ferramentas LangGraph
tools = api2tool("./openapi.json")

# Ou de uma URL
tools = api2tool("https://petstore.swagger.io/v2/swagger.json")

# Especificar URL base customizada
tools = api2tool("./openapi.json", base_url="https://api.exemplo.com")
```

### 2. Diferentes Formatos de Sa√≠da

```python
# Lista de ferramentas (padr√£o)
tools = api2tool("./openapi.json", output_format="tools")

# Dicion√°rio com operation_id como chave
tools_dict = api2tool("./openapi.json", output_format="dict")

# Gerar arquivo Python
code = api2tool("./openapi.json", output_format="file")

# Apenas nomes das ferramentas
names = api2tool("./openapi.json", output_format="names")

# Informa√ß√µes sobre a API
info = api2tool("./openapi.json", output_format="info")
```

### 3. Configura√ß√£o de LLM

#### AWS Bedrock (Recomendado para Produ√ß√£o)
```python
from agentCore.providers import get_llm, get_embeddings

# Configurar AWS Bedrock (padr√£o)
llm = get_llm("bedrock")
embeddings = get_embeddings("bedrock")
```

Vari√°veis de ambiente necess√°rias:
```bash
export AWS_REGION=us-east-1
export BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key
# ou configure via AWS CLI / IAM roles
```

#### Outros Provedores
```python
# OpenAI
llm = get_llm("openai")  # Requer OPENAI_API_KEY

# Ollama (desenvolvimento local)
llm = get_llm("ollama")  # Requer Ollama rodando localmente

# Google Gemini
llm = get_llm("gemini")  # Requer GEMINI_API_KEY
```

### 4. Cria√ß√£o de Agente Completo

```python
from agentCore.utils import api2tool
from agentCore.providers import get_llm
from agentCore.graphs import create_agent_graph

# 1. Configurar LLM (Bedrock por padr√£o)
llm = get_llm()

# 2. Converter API para ferramentas
tools = api2tool("./openapi.json")
tool_functions = [tool['function'] for tool in tools]

# 3. Criar agente com grafo
agent = create_agent_graph(llm, tools=tool_functions)

# 4. Usar o agente
from langchain_core.messages import HumanMessage

result = agent.invoke({
    "messages": [HumanMessage(content="Qual √© o clima hoje?")]
})

print(result["messages"][-1].content)
```

## ‚öôÔ∏è Configura√ß√£o Avan√ßada

### Arquivo .env
```bash
# Provedor principal (padr√£o: bedrock)
MAIN_PROVIDER=bedrock

# AWS Bedrock
AWS_REGION=us-east-1
BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
BEDROCK_EMBEDDINGS_MODEL=amazon.titan-embed-text-v1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# OpenAI (opcional)
OPENAI_API_KEY=your_openai_key
OPENAI_MODEL=gpt-4

# Ollama (opcional)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:latest

# Google Gemini (opcional)
GEMINI_API_KEY=your_gemini_key
GEMINI_MODEL=gemini-1.5-flash
```

### Logging Personalizado
```python
from agentCore.logger import get_logger

# Logger espec√≠fico para seu componente
logger = get_logger("minha_aplicacao")

logger.info("Aplica√ß√£o iniciada")
logger.success("Opera√ß√£o conclu√≠da com sucesso")
logger.error("Erro na aplica√ß√£o")
```

## üìö Exemplos Completos

### Exemplo 1: Agente de Clima
```python
from agentCore.utils import api2tool
from agentCore.providers import get_llm
from agentCore.graphs import create_agent_graph
from langchain_core.messages import HumanMessage

# Configurar LLM
llm = get_llm("bedrock")

# Carregar ferramentas de API de clima
tools = api2tool("https://api.openweathermap.org/data/2.5/swagger.json")
tool_functions = [tool['function'] for tool in tools]

# Criar agente
agent = create_agent_graph(llm, tools=tool_functions)

# Usar agente
response = agent.invoke({
    "messages": [HumanMessage(content="Qual a temperatura em S√£o Paulo?")]
})

print(response["messages"][-1].content)
```

### Exemplo 2: Sistema Multi-API
```python
from agentCore.utils import api2tool
from agentCore.providers import get_llm
from agentCore.graphs import create_agent_graph

# Combinar m√∫ltiplas APIs
weather_tools = api2tool("./weather_api.json")
news_tools = api2tool("./news_api.json")

# Combinar todas as ferramentas
all_tools = []
all_tools.extend([tool['function'] for tool in weather_tools])
all_tools.extend([tool['function'] for tool in news_tools])

# Criar agente √∫nico com todas as ferramentas
llm = get_llm()
agent = create_agent_graph(llm, tools=all_tools)
```

## üèóÔ∏è Arquitetura

```
agentCore/
‚îú‚îÄ‚îÄ utils/           # Utilidades principais
‚îÇ   ‚îú‚îÄ‚îÄ api2tool.py     # Convers√£o OpenAPI ‚Üí Ferramentas
‚îÇ   ‚îî‚îÄ‚îÄ openapi_to_tools.py
‚îú‚îÄ‚îÄ providers/       # Provedores LLM
‚îÇ   ‚îî‚îÄ‚îÄ llm_providers.py
‚îú‚îÄ‚îÄ graphs/         # Orquestra√ß√£o LangGraph
‚îÇ   ‚îî‚îÄ‚îÄ graph.py
‚îî‚îÄ‚îÄ logger/         # Sistema de logging
    ‚îî‚îÄ‚îÄ logger.py
```

## üîß Desenvolvimento

### Configurar ambiente de desenvolvimento
```bash
git clone <repositorio>
cd agentcore
pip install -e .[dev]
```

### Executar testes
```bash
pytest
pytest --cov=agentCore  # com cobertura
```

### Formata√ß√£o de c√≥digo
```bash
black agentCore/
isort agentCore/
flake8 agentCore/
```

## üìÑ Licen√ßa

MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìû Suporte

- **Issues**: [GitHub Issues](https://github.com/your-org/agent-core/issues)
- **Documenta√ß√£o**: [ReadTheDocs](https://agent-core.readthedocs.io)
- **Discuss√µes**: [GitHub Discussions](https://github.com/your-org/agent-core/discussions)